.text
.global CRYPTO_NAMESPACE(secp256k1_fe_mul_inner)
CRYPTO_NAMESPACE(secp256k1_fe_mul_inner):
	sub    $0xc0,%rsp
	mov    %rdx,%rax
	mov    0x20(%rsi),%rdx
	mulx   0x8(%rax),%r10,%r11
	mov    0x8(%rsi),%rdx
	mulx   0x10(%rax),%rcx,%r8
	mov    0x10(%rax),%rdx
	mov    %rbx,(%rsp)
	mulx   0x20(%rsi),%r9,%rbx
	mov    0x8(%rax),%rdx
	mov    %rbp,0x8(%rsp)
	mov    %r12,0x10(%rsp)
	mulx   (%rsi),%rbp,%r12
	mov    0x10(%rsi),%rdx
	mov    %r13,0x18(%rsp)
	mov    %r14,0x20(%rsp)
	mulx   0x18(%rax),%r13,%r14
	mov    (%rsi),%rdx
	mov    %r15,0x28(%rsp)
	mov    %rdi,0x30(%rsp)
	mulx   0x20(%rax),%r15,%rdi
	mov    0x8(%rax),%rdx
	mov    %rdi,0x38(%rsp)
	mov    %r15,0x40(%rsp)
	mulx   0x10(%rsi),%rdi,%r15
	mov    0x10(%rsi),%rdx
	mov    %r15,0x48(%rsp)
	mov    %rdi,0x50(%rsp)
	mulx   0x10(%rax),%r15,%rdi
	mov    (%rax),%rdx
	mov    %rdi,0x58(%rsp)
	mov    %r15,0x60(%rsp)
	mulx   0x8(%rsi),%rdi,%r15
	mov    0x20(%rsi),%rdx
	mov    %r8,0x68(%rsp)
	mov    %rcx,0x70(%rsp)
	mulx   0x20(%rax),%r8,%rcx
	mov    0x18(%rsi),%rdx
	mov    %rcx,0x78(%rsp)
	mov    %r8,0x80(%rsp)
	mulx   0x10(%rax),%rcx,%r8
	test   %al,%al
	adox   %rcx,%r13
	adox   %r14,%r8
	mov    0x18(%rsi),%rdx
	mulx   0x18(%rax),%r14,%rcx
	adcx   %r9,%r14
	adcx   %rcx,%rbx
	mov    0x10(%rsi),%rdx
	mulx   0x20(%rax),%r9,%rcx
	add    %r13,%r10
	adcx   %r11,%r8
	mov    0x18(%rax),%rdx
	mulx   0x8(%rsi),%r11,%r13
	xor    %rdx,%rdx
	adox   %rdi,%rbp
	adox   %r12,%r15
	adcx   %r14,%r9
	adcx   %rcx,%rbx
	mov    0x10(%rax),%rdx
	mulx   (%rsi),%r12,%rdi
	mov    0x18(%rax),%rdx
	mulx   (%rsi),%r14,%rcx
	xor    %rdx,%rdx
	adox   0x70(%rsp),%r14
	adox   0x68(%rsp),%rcx
	mov    0x8(%rax),%rdx
	mov    %r15,0x88(%rsp)
	mov    %rbp,0x90(%rsp)
	mulx   0x8(%rsi),%r15,%rbp
	adcx   %r15,%r12
	adcx   %rdi,%rbp
	mov    0x20(%rsi),%rdx
	mulx   0x18(%rax),%rdi,%r15
	mov    0x18(%rsi),%rdx
	mov    %rbx,0x98(%rsp)
	mov    %r9,0xa0(%rsp)
	mulx   0x20(%rax),%rbx,%r9
	mov    0x10(%rsi),%rdx
	mov    %r8,0xa8(%rsp)
	mov    %r10,0xb0(%rsp)
	mulx   (%rax),%r8,%r10
	add    %rbx,%rdi
	adcx   %r15,%r9
	add    %r12,%r8
	adcx   %r10,%rbp
	mov    0x18(%rsi),%rdx
	mulx   0x8(%rax),%r12,%r15
	mov    %r14,%rdx
	test   %al,%al
	adox   0x50(%rsp),%rdx
	adox   0x48(%rsp),%rcx
	adcx   0x60(%rsp),%r11
	adcx   0x58(%rsp),%r13
	mov    $0x40,%r14d
	bzhi   %r14,0x80(%rsp),%rbx
	adox   %r11,%r12
	adox   %r15,%r13
	movabs $0x1000003d10,%r10
	xchg   %rdx,%rbx
	mulx   %r10,%r15,%r11
	mov    (%rax),%rdx
	mulx   0x18(%rsi),%r14,%r10
	mov    0x78(%rsp),%rdx
	add    %rbx,%r14
	adcx   %r10,%rcx
	xor    %rbx,%rbx
	adox   %r14,%r15
	adox   %r11,%rcx
	mov    %rdx,%r11
	mov    (%rax),%rdx
	mulx   0x20(%rsi),%r10,%r14
	movabs $0x1000003d10000,%rdx
	mov    %rbp,0xb8(%rsp)
	mulx   %r11,%rbx,%rbp
	adcx   %r12,%r10
	adcx   %r14,%r13
	mov    0x20(%rax),%rdx
	mulx   0x8(%rsi),%r12,%r11
	test   %al,%al
	adox   0xb0(%rsp),%r12
	adox   0xa8(%rsp),%r11
	mov    %r10,%rdx
	adcx   0x40(%rsp),%rdx
	adcx   0x38(%rsp),%r13
	mov    %r15,%r14
	shrd   $0x34,%rcx,%r14
	shr    $0x34,%rcx
	xor    %r10,%r10
	adox   %rdx,%rbx
	adox   %rbp,%r13
	adcx   %rbx,%r14
	adcx   %rcx,%r13
	mov    %r14,%rbp
	shrd   $0x34,%r13,%rbp
	mov    $0x34,%edx
	sarx   %rdx,%r13,%rdx
	xor    %rcx,%rcx
	adox   %r12,%rbp
	adox   %rdx,%r11
	mov    %rbp,%r10
	mov    $0x34,%r12d
	bzhi   %r12,%r15,%rbx
	shrd   $0x34,%r11,%rbp
	mov    $0x34,%r15d
	sarx   %r15,%r11,%r15
	shl    $0x4,%r10
	add    0xa0(%rsp),%rbp
	adcx   0x98(%rsp),%r15
	bzhi   %r12,%rbp,%r13
	movabs $0x1000003d10,%rdx
	mulx   %r13,%r11,%rcx
	mov    %r14,%r13
	shrd   $0x34,%r15,%rbp
	mov    $0x34,%edx
	sarx   %rdx,%r15,%rdx
	add    %rdi,%rbp
	adcx   %rdx,%r9
	mov    $0xffffffffffffffff,%rdi
	and    %rdi,%rbp
	shr    $0x30,%r13
	mov    $0xf,%r15d
	and    %r15,%r13
	movabs $0x1000003d10,%rdx
	mulx   %rbp,%r15,%r12
	adox   %r8,%r15
	adox   0xb8(%rsp),%r12
	movabs $0xfffffffffffff0,%r8
	and    %r8,%r10
	or     %r13,%r10
	movabs $0x1000003d10000,%rbp
	mov    %rbp,%rdx
	mulx   %r9,%rbp,%r13
	movabs $0x1000003d1,%r9
	mov    %r9,%rdx
	mulx   %r10,%r9,%r8
	mov    (%rsi),%rdx
	mulx   (%rax),%r10,%rdi
	adox   %r9,%r10
	adox   %rdi,%r8
	adcx   %rbp,%rbx
	adc    $0x0,%r13
	xor    %rdx,%rdx
	adox   0x90(%rsp),%r11
	adox   0x88(%rsp),%rcx
	mov    %r10,%rbp
	shrd   $0x34,%r8,%rbp
	shr    $0x34,%r8
	xor    %r9,%r9
	adox   %r11,%rbp
	adox   %r8,%rcx
	mov    %rbp,%rdx
	shrd   $0x34,%rcx,%rbp
	shr    $0x34,%rcx
	movabs $0xfffffffffffff,%rdi
	and    %rdi,%rdx
	and    %rdi,%r10
	mov    0x30(%rsp),%r11
	mov    %r10,(%r11)
	mov    %rdx,0x8(%r11)
	adox   %r15,%rbp
	adox   %rcx,%r12
	mov    $0x30,%r15d
	bzhi   %r15,%r14,%r8
	mov    %rbp,%r14
	shrd   $0x34,%r12,%r14
	shr    $0x34,%r12
	add    %rbx,%r14
	adcx   %r12,%r13
	mov    %r14,%rbx
	shrd   $0x34,%r13,%r14
	shr    $0x34,%r13
	add    %r14,%r8
	adc    $0x0,%r13
	mov    %r8,0x20(%r11)
	and    %rdi,%rbx
	and    %rdi,%rbp
	mov    %rbp,0x10(%r11)
	mov    %rbx,0x18(%r11)
	mov    (%rsp),%rbx
	mov    0x8(%rsp),%rbp
	mov    0x10(%rsp),%r12
	mov    0x18(%rsp),%r13
	mov    0x20(%rsp),%r14
	mov    0x28(%rsp),%r15
	add    $0xc0,%rsp
	ret
.text
.global CRYPTO_NAMESPACE(secp256k1_fe_sqr_inner)
CRYPTO_NAMESPACE(secp256k1_fe_sqr_inner):
	sub    $0x60,%rsp
	mov    $0x1,%eax
	shlx   %rax,0x20(%rsi),%r10
	shlx   %rax,(%rsi),%r11
	mov    0x8(%rsi),%rdx
	mulx   %rdx,%rcx,%r8
	mov    0x20(%rsi),%rdx
	mulx   %rdx,%r9,%rax
	mov    $0x40,%edx
	mov    %rbx,(%rsp)
	bzhi   %rdx,%r9,%rbx
	mov    $0x1,%r9d
	mov    %rbp,0x8(%rsp)
	shlx   %r9,0x10(%rsi),%rbp
	mov    0x8(%rsi),%rdx
	mov    %r12,0x10(%rsp)
	mulx   %r10,%r9,%r12
	mov    %rbp,%rdx
	mov    %r13,0x18(%rsp)
	mulx   0x18(%rsi),%rbp,%r13
	mov    0x18(%rsi),%rdx
	mov    %r14,0x20(%rsp)
	mov    %r15,0x28(%rsp)
	mulx   %r11,%r14,%r15
	adox   %r9,%rbp
	adox   %r13,%r12
	mov    $0x1,%edx
	shlx   %rdx,0x8(%rsi),%r9
	mov    %r9,%rdx
	mulx   0x10(%rsi),%r9,%r13
	mov    %rdi,0x30(%rsp)
	mov    %rdx,%rdi
	mov    0x8(%rsi),%rdx
	mov    %r12,0x38(%rsp)
	mov    %rbp,0x40(%rsp)
	mulx   %r11,%r12,%rbp
	mov    0x10(%rsi),%rdx
	mov    %rbp,0x48(%rsp)
	mov    %r12,0x50(%rsp)
	mulx   %r11,%rbp,%r12
	add    %rbp,%rcx
	adcx   %r8,%r12
	movabs $0x1000003d10000,%rdx
	mulx   %rax,%r11,%r8
	movabs $0x1000003d10,%rax
	mov    %rbx,%rdx
	mulx   %rax,%rbx,%rbp
	xor    %rdx,%rdx
	adox   %r14,%r9
	adox   %r13,%r15
	adcx   %r9,%rbx
	adcx   %rbp,%r15
	mov    %rbx,%r14
	shrd   $0x34,%r15,%r14
	shr    $0x34,%r15
	mov    0x18(%rsi),%rdx
	mulx   %rdi,%r13,%rbp
	mov    0x10(%rsi),%rdx
	mulx   %rdx,%rdi,%r9
	mov    (%rsi),%rdx
	mov    %r12,0x58(%rsp)
	mulx   %r10,%rax,%r12
	xor    %rdx,%rdx
	adox   %r13,%rdi
	adox   %r9,%rbp
	adcx   %rdi,%rax
	adcx   %r12,%rbp
	test   %al,%al
	adox   %rax,%r11
	adox   %r8,%rbp
	movabs $0xffffffffffffe,%r8
	and    %r8,%rbx
	adox   %r11,%r14
	adox   %r15,%rbp
	mov    %r14,%r15
	mov    $0x30,%r13d
	bzhi   %r13,%r14,%r9
	shrd   $0x34,%rbp,%r14
	shr    $0x34,%rbp
	add    0x40(%rsp),%r14
	adcx   0x38(%rsp),%rbp
	mov    %r14,%r12
	shr    $0x30,%r15
	shrd   $0x34,%rbp,%r14
	shr    $0x34,%rbp
	mov    0x18(%rsi),%rdx
	mulx   %rdx,%rdi,%rax
	mov    0x10(%rsi),%rdx
	mulx   %r10,%r11,%r13
	xor    %rdx,%rdx
	adox   %r11,%rdi
	adox   %rax,%r13
	adcx   %rdi,%r14
	adcx   %rbp,%r13
	mov    (%rsi),%rdx
	mulx   %rdx,%rbp,%rax
	mov    $0xf,%edx
	and    %rdx,%r15
	shl    $0x4,%r12
	mov    $0x34,%r11d
	bzhi   %r11,%r14,%rdi
	movabs $0xfffffffffffff0,%rdx
	and    %rdx,%r12
	or     %r15,%r12
	movabs $0x1000003d1,%r15
	mov    %r15,%rdx
	mulx   %r12,%r15,%r8
	adox   %r15,%rbp
	adox   %rax,%r8
	mov    %rbp,%rax
	bzhi   %r11,%rax,%r12
	mov    0x18(%rsi),%rdx
	mulx   %r10,%r15,%rax
	shrd   $0x34,%r13,%r14
	shr    $0x34,%r13
	xor    %rdx,%rdx
	adox   %r14,%r15
	adox   %rax,%r13
	shrd   $0x34,%r8,%rbp
	shr    $0x34,%r8
	mov    0x30(%rsp),%r10
	mov    %r12,(%r10)
	movabs $0x1000003d10,%r12
	mov    %r12,%rdx
	mulx   %rdi,%r12,%rax
	mov    $0x40,%edi
	bzhi   %rdi,%r15,%r14
	mulx   %r14,%r15,%rdi
	mov    %r12,%r14
	adox   0x50(%rsp),%r14
	adox   0x48(%rsp),%rax
	add    %r14,%rbp
	adcx   %r8,%rax
	movabs $0x1000003d10000,%r8
	mov    %r13,%rdx
	mulx   %r8,%r13,%r12
	mov    %rbp,%rdx
	shrd   $0x34,%rax,%rdx
	shr    $0x34,%rax
	add    %rcx,%r15
	adcx   0x58(%rsp),%rdi
	xor    %rcx,%rcx
	adox   %r15,%rdx
	adox   %rax,%rdi
	bzhi   %r11,%rbp,%r14
	mov    %rdx,%rax
	mov    %r14,0x8(%r10)
	adox   %r13,%rbx
	adox   %rcx,%r12
	bzhi   %r11,%rax,%r13
	shrd   $0x34,%rdi,%rdx
	shr    $0x34,%rdi
	xor    %r15,%r15
	adox   %rbx,%rdx
	adox   %rdi,%r12
	mov    %rdx,%rcx
	shrd   $0x34,%r12,%rcx
	shr    $0x34,%r12
	xor    %rbp,%rbp
	adox   %rcx,%r9
	adox   %rbp,%r12
	mov    %r9,0x20(%r10)
	mov    %r13,0x10(%r10)
	bzhi   %r11,%rdx,%r15
	mov    %r15,0x18(%r10)
	mov    (%rsp),%rbx
	mov    0x8(%rsp),%rbp
	mov    0x10(%rsp),%r12
	mov    0x18(%rsp),%r13
	mov    0x20(%rsp),%r14
	mov    0x28(%rsp),%r15
	add    $0x60,%rsp
	ret
