.text
.global CRYPTO_NAMESPACE(secp256k1_fe_mul_inner)
CRYPTO_NAMESPACE(secp256k1_fe_mul_inner):
	mov    %rdx,%rax
	mov    0x20(%rsi),%rdx
	mulx   0x20(%rax),%r10,%r11
	mov    0x18(%rax),%rdx
	mulx   (%rsi),%rcx,%r8
	mov    0x8(%rax),%rdx
	mov    %rbx,-0x80(%rsp)
	mulx   0x20(%rsi),%r9,%rbx
	mov    0x18(%rax),%rdx
	mov    %rbp,-0x78(%rsp)
	mov    %r12,-0x70(%rsp)
	mulx   0x8(%rsi),%rbp,%r12
	mov    0x10(%rax),%rdx
	mov    %r13,-0x68(%rsp)
	mov    %r14,-0x60(%rsp)
	mulx   0x8(%rsi),%r13,%r14
	mov    $0xffffffffffffffff,%rdx
	and    %rdx,%r10
	adox   %r13,%rcx
	adox   %r8,%r14
	mov    0x10(%rsi),%rdx
	mulx   0x10(%rax),%r8,%r13
	adcx   %r8,%rbp
	adcx   %r12,%r13
	movabs $0x1000003d10000,%rdx
	mulx   %r11,%r12,%r8
	mov    0x10(%rsi),%rdx
	mov    %r15,-0x58(%rsp)
	mulx   0x8(%rax),%r11,%r15
	test   %al,%al
	adox   %rcx,%r11
	adox   %r15,%r14
	mov    (%rax),%rdx
	mulx   0x18(%rsi),%rcx,%r15
	adcx   %r11,%rcx
	adcx   %r15,%r14
	movabs $0x1000003d10,%rdx
	mulx   %r10,%r11,%r15
	mov    0x18(%rsi),%rdx
	mov    %rdi,-0x50(%rsp)
	mulx   0x8(%rax),%r10,%rdi
	xor    %rdx,%rdx
	adox   %rbp,%r10
	adox   %rdi,%r13
	mov    (%rax),%rdx
	mulx   0x20(%rsi),%rbp,%rdi
	adcx   %rcx,%r11
	adcx   %r15,%r14
	mov    0x20(%rax),%rdx
	mulx   (%rsi),%rcx,%r15
	test   %al,%al
	adox   %r10,%rbp
	adox   %rdi,%r13
	mov    %r11,%rdx
	shrd   $0x34,%r14,%rdx
	shr    $0x34,%r14
	xor    %r10,%r10
	adox   %rbp,%rcx
	adox   %r15,%r13
	adcx   %rcx,%r12
	adcx   %r8,%r13
	add    %r12,%rdx
	adcx   %r14,%r13
	mov    %rdx,%r8
	mov    0x10(%rsi),%rdx
	mulx   0x18(%rax),%rdi,%r15
	mov    0x10(%rax),%rdx
	mulx   0x18(%rsi),%rbp,%r14
	add    %rbp,%rdi
	adcx   %r15,%r14
	mov    %r8,%rdx
	mov    %rdx,%rcx
	mov    0x20(%rax),%rdx
	mulx   0x8(%rsi),%r12,%r15
	mov    %r8,%rdx
	shrd   $0x34,%r13,%rdx
	mov    $0x34,%ebp
	sarx   %rbp,%r13,%rbp
	add    %rdi,%r9
	adcx   %rbx,%r14
	xor    %rbx,%rbx
	adox   %r9,%r12
	adox   %r15,%r14
	adcx   %r12,%rdx
	adcx   %rbp,%r14
	shr    $0x30,%rcx
	mov    %rdx,%r10
	mov    0x10(%rax),%rdx
	mulx   0x20(%rsi),%r13,%rdi
	mov    $0xf,%edx
	and    %rdx,%rcx
	mov    $0x30,%r15d
	bzhi   %r15,%r8,%rbp
	mov    0x18(%rax),%rdx
	mulx   0x18(%rsi),%r8,%r9
	mov    0x10(%rsi),%rdx
	mulx   0x20(%rax),%r12,%rbx
	mov    %r10,%rdx
	shrd   $0x34,%r14,%rdx
	mov    $0x34,%r15d
	sarx   %r15,%r14,%r15
	test   %al,%al
	adox   %r13,%r8
	adox   %r9,%rdi
	adcx   %r8,%r12
	adcx   %rbx,%rdi
	xor    %r14,%r14
	adox   %r12,%rdx
	adox   %r15,%rdi
	mov    %rdx,%r13
	shrd   $0x34,%rdi,%r13
	mov    $0x34,%r9d
	sarx   %r9,%rdi,%r9
	mov    %rdx,%rbx
	mov    0x18(%rsi),%rdx
	mulx   0x20(%rax),%r15,%r8
	movabs $0xfffffffffffff,%rdx
	and    %rdx,%rbx
	lea    0x0(,%r10,8),%r12
	lea    (%r12,%r12,1),%r12
	movabs $0xfffffffffffff0,%r10
	and    %r10,%r12
	mov    (%rsi),%rdx
	mulx   0x10(%rax),%rdi,%r14
	mov    0x20(%rsi),%rdx
	mov    %rbp,-0x48(%rsp)
	mulx   0x18(%rax),%r10,%rbp
	adox   %r15,%r10
	adox   %rbp,%r8
	adcx   %r10,%r13
	adcx   %r9,%r8
	mov    0x8(%rsi),%rdx
	mulx   (%rax),%r9,%r15
	or     %rcx,%r12
	movabs $0x1000003d1,%rdx
	mulx   %r12,%rcx,%rbp
	mov    0x8(%rax),%rdx
	mulx   0x8(%rsi),%r10,%r12
	adox   %r10,%rdi
	adox   %r14,%r12
	mov    (%rsi),%rdx
	mulx   0x8(%rax),%r14,%r10
	mov    (%rsi),%rdx
	mov    %r8,-0x40(%rsp)
	mov    %r12,-0x38(%rsp)
	mulx   (%rax),%r8,%r12
	adcx   %rcx,%r8
	adcx   %r12,%rbp
	xor    %rdx,%rdx
	adox   %r9,%r14
	adox   %r10,%r15
	movabs $0x1000003d10,%r9
	mov    %rbx,%rdx
	mulx   %r9,%rbx,%rcx
	adcx   %r14,%rbx
	adcx   %rcx,%r15
	mov    %r8,%rdx
	movabs $0xfffffffffffff,%r10
	and    %r10,%rdx
	shrd   $0x34,%rbp,%r8
	shr    $0x34,%rbp
	mov    %rdx,%r12
	mov    (%rax),%rdx
	mulx   0x10(%rsi),%r14,%rcx
	xor    %rdx,%rdx
	adox   %rbx,%r8
	adox   %rbp,%r15
	mov    %r8,%rbx
	shrd   $0x34,%r15,%rbx
	shr    $0x34,%r15
	mov    $0x40,%ebp
	bzhi   %rbp,%r13,%rdx
	adox   %rdi,%r14
	adox   -0x38(%rsp),%rcx
	mulx   %r9,%r13,%rdi
	xor    %rdx,%rdx
	adox   %r14,%r13
	adox   %rdi,%rcx
	adcx   %r13,%rbx
	adcx   %r15,%rcx
	mov    %rbx,%r15
	shrd   $0x34,%rcx,%r15
	shr    $0x34,%rcx
	and    %r10,%rbx
	movabs $0x1000003d10000,%r14
	mov    %r14,%rdx
	mulx   -0x40(%rsp),%r14,%rdi
	and    %r10,%r11
	adox   %r14,%r11
	mov    $0x0,%r13d
	adox   %r13,%rdi
	mov    -0x50(%rsp),%r14
	mov    %rbx,0x10(%r14)
	adcx   %r11,%r15
	adcx   %rcx,%rdi
	mov    %r15,%rcx
	shrd   $0x34,%rdi,%r15
	shr    $0x34,%rdi
	and    %r10,%r8
	mov    %r15,%rbx
	adox   -0x48(%rsp),%rbx
	adox   %r13,%rdi
	mov    %rbx,0x20(%r14)
	mov    %r8,0x8(%r14)
	and    %r10,%rcx
	mov    %rcx,0x18(%r14)
	mov    %r12,(%r14)
	mov    -0x80(%rsp),%rbx
	mov    -0x78(%rsp),%rbp
	mov    -0x70(%rsp),%r12
	mov    -0x68(%rsp),%r13
	mov    -0x60(%rsp),%r14
	mov    -0x58(%rsp),%r15
	ret
