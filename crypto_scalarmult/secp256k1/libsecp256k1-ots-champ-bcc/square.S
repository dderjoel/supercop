.text
.global CRYPTO_NAMESPACE(secp256k1_fe_sqr_inner)
CRYPTO_NAMESPACE(secp256k1_fe_sqr_inner):
	imul   $0x2,(%rsi),%rax
	mov    0x18(%rsi),%rdx
	mulx   %rax,%r10,%r11
	mov    0x20(%rsi),%rdx
	mulx   %rdx,%rcx,%r8
	mov    $0x40,%edx
	bzhi   %rdx,%rcx,%r9
	movabs $0x1000003d10,%rcx
	mov    %r9,%rdx
	mov    %rbx,-0x80(%rsp)
	mulx   %rcx,%r9,%rbx
	mov    0x8(%rsi),%rdx
	mov    %rbp,-0x78(%rsp)
	lea    (%rdx,%rdx,1),%rbp
	mov    0x10(%rsi),%rdx
	mov    %r12,-0x70(%rsp)
	mov    %r13,-0x68(%rsp)
	mulx   %rbp,%r12,%r13
	adox   %r10,%r12
	adox   %r13,%r11
	mov    %rbp,%rdx
	mulx   0x18(%rsi),%rbp,%r10
	mov    0x20(%rsi),%rdx
	lea    (%rdx,%rdx,1),%r13
	mov    %rax,%rdx
	mov    %r14,-0x60(%rsp)
	mulx   0x8(%rsi),%rax,%r14
	mov    %r15,-0x58(%rsp)
	mov    %rdx,%r15
	mov    0x10(%rsi),%rdx
	mov    %rdi,-0x50(%rsp)
	mulx   %rdx,%rcx,%rdi
	add    %r12,%r9
	adcx   %rbx,%r11
	movabs $0x1000003d10000,%rdx
	mulx   %r8,%rbx,%r12
	add    %rbp,%rcx
	adcx   %rdi,%r10
	mov    %r13,%rdx
	mulx   (%rsi),%r13,%r8
	xor    %rbp,%rbp
	adox   %rcx,%r13
	adox   %r8,%r10
	adcx   %r13,%rbx
	adcx   %r12,%r10
	mov    %r9,%rdi
	shrd   $0x34,%r11,%rdi
	shr    $0x34,%r11
	test   %al,%al
	adox   %rbx,%rdi
	adox   %r11,%r10
	mov    %rdi,%r12
	shr    $0x30,%r12
	imul   $0x2,0x10(%rsi),%rcx
	mov    $0xf,%r8d
	and    %r8,%r12
	mov    %rdi,%r13
	shrd   $0x34,%r10,%r13
	shr    $0x34,%r10
	mulx   0x8(%rsi),%rbx,%r11
	xchg   %rdx,%rcx
	mulx   0x18(%rsi),%rbp,%r8
	xor    %rdx,%rdx
	adox   %rbx,%rbp
	adox   %r8,%r11
	adcx   %rbp,%r13
	adcx   %r10,%r11
	mov    %r13,%r10
	shl    $0x4,%r10
	mov    0x18(%rsi),%rdx
	mulx   %rdx,%rbx,%r8
	mov    0x10(%rsi),%rdx
	mov    %r14,-0x48(%rsp)
	mulx   %rcx,%rbp,%r14
	xor    %rdx,%rdx
	adox   %rbp,%rbx
	adox   %r8,%r14
	shrd   $0x34,%r11,%r13
	shr    $0x34,%r11
	xor    %r8,%r8
	adox   %rbx,%r13
	adox   %r11,%r14
	mov    %r13,%rdx
	shrd   $0x34,%r14,%rdx
	shr    $0x34,%r14
	mov    %rdx,%rbp
	mov    0x18(%rsi),%rdx
	mulx   %rcx,%rbx,%r11
	mov    (%rsi),%rdx
	mulx   %rdx,%rcx,%r8
	movabs $0xfffffffffffff0,%rdx
	and    %rdx,%r10
	adox   %rbp,%rbx
	adox   %r11,%r14
	or     %r12,%r10
	movabs $0x1000003d1,%r12
	mov    %r10,%rdx
	mulx   %r12,%r10,%rbp
	movabs $0x1000003d10000,%r11
	mov    %r11,%rdx
	mulx   %r14,%r11,%r12
	adox   %r10,%rcx
	adox   %r8,%rbp
	mov    %rcx,%r8
	movabs $0xfffffffffffff,%r14
	and    %r14,%r13
	shrd   $0x34,%rbp,%rcx
	shr    $0x34,%rbp
	movabs $0x1000003d10,%r10
	mov    %r13,%rdx
	mulx   %r10,%r13,%r14
	xor    %rdx,%rdx
	adox   %r13,%rax
	adox   -0x48(%rsp),%r14
	adcx   %rax,%rcx
	adcx   %rbp,%r14
	mov    %rcx,%rbp
	shrd   $0x34,%r14,%rbp
	shr    $0x34,%r14
	mov    0x10(%rsi),%rdx
	mulx   %r15,%r13,%rax
	mov    $0xffffffffffffffff,%rdx
	and    %rdx,%rbx
	movabs $0xffffffffffffe,%r15
	and    %r15,%r9
	mov    0x8(%rsi),%rdx
	mulx   %rdx,%r15,%r10
	adox   %r13,%r15
	adox   %r10,%rax
	movabs $0x1000003d10,%rdx
	mulx   %rbx,%r13,%r10
	adcx   %r15,%r13
	adcx   %r10,%rax
	test   %al,%al
	adox   %r13,%rbp
	adox   %r14,%rax
	mov    %rbp,%r14
	adcx   %r11,%r9
	adc    $0x0,%r12
	shrd   $0x34,%rax,%rbp
	shr    $0x34,%rax
	xor    %r11,%r11
	adox   %r9,%rbp
	adox   %rax,%r12
	mov    %rbp,%rbx
	mov    $0x30,%r15d
	bzhi   %r15,%rdi,%r10
	shrd   $0x34,%r12,%rbp
	shr    $0x34,%r12
	movabs $0xfffffffffffff,%rdi
	and    %rdi,%rbx
	mov    -0x50(%rsp),%r13
	mov    %rbx,0x18(%r13)
	adox   %rbp,%r10
	adox   %r11,%r12
	and    %rdi,%r8
	mov    %r8,0x0(%r13)
	and    %rdi,%r14
	and    %rdi,%rcx
	mov    %rcx,0x8(%r13)
	mov    %r10,0x20(%r13)
	mov    %r14,0x10(%r13)
	mov    -0x80(%rsp),%rbx
	mov    -0x78(%rsp),%rbp
	mov    -0x70(%rsp),%r12
	mov    -0x68(%rsp),%r13
	mov    -0x60(%rsp),%r14
	mov    -0x58(%rsp),%r15
	ret
