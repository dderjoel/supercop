.text
.global CRYPTO_NAMESPACE(secp256k1_fe_sqr_inner)
CRYPTO_NAMESPACE(secp256k1_fe_sqr_inner):
	imul   $0x2,0x10(%rsi),%rax
	mov    0x8(%rsi),%r10
	lea    (%r10,%r10,1),%r11
	mov    0x10(%rsi),%rdx
	mulx   %rdx,%r10,%rcx
	mov    %r11,%rdx
	mulx   0x10(%rsi),%r11,%r8
	mov    %rbx,-0x80(%rsp)
	mulx   0x18(%rsi),%r9,%rbx
	add    %r9,%r10
	adcx   %rcx,%rbx
	mov    $0x1,%edx
	shlx   %rdx,(%rsi),%rcx
	mov    0x20(%rsi),%rdx
	mov    %rbp,-0x78(%rsp)
	mulx   %rdx,%r9,%rbp
	mov    %rax,%rdx
	mov    %r12,-0x70(%rsp)
	mulx   0x18(%rsi),%rax,%r12
	mov    %rcx,%rdx
	mov    %r13,-0x68(%rsp)
	mulx   0x8(%rsi),%rcx,%r13
	mov    %r14,-0x60(%rsp)
	mov    %r15,-0x58(%rsp)
	mulx   0x10(%rsi),%r14,%r15
	mov    %rdi,-0x50(%rsp)
	mov    $0xffffffffffffffff,%rdi
	and    %rdi,%r9
	mov    %r15,-0x48(%rsp)
	mulx   0x18(%rsi),%rdi,%r15
	movabs $0x1000003d10,%rdx
	mov    %r14,-0x40(%rsp)
	mov    %r13,-0x38(%rsp)
	mulx   %r9,%r14,%r13
	adox   %rdi,%r11
	adox   %r8,%r15
	adcx   %r11,%r14
	adcx   %r13,%r15
	imul   $0x2,0x20(%rsi),%r8
	mov    (%rsi),%rdx
	mulx   %r8,%r9,%rdi
	movabs $0x1000003d10000,%rdx
	mulx   %rbp,%r13,%r11
	xor    %rbp,%rbp
	adox   %r10,%r9
	adox   %rdi,%rbx
	mov    %r14,%r10
	shrd   $0x34,%r15,%r10
	shr    $0x34,%r15
	test   %al,%al
	adox   %r9,%r13
	adox   %r11,%rbx
	adcx   %r13,%r10
	adcx   %r15,%rbx
	mov    %r10,%rdi
	mov    %r10,%r11
	shrd   $0x34,%rbx,%r11
	shr    $0x34,%rbx
	movabs $0xffffffffffffe,%r9
	and    %r9,%r14
	mov    %r8,%rdx
	mulx   0x8(%rsi),%r8,%r15
	adox   %r8,%rax
	adox   %r12,%r15
	adcx   %rax,%r11
	adcx   %rbx,%r15
	mov    %r11,%r12
	shl    $0x4,%r12
	shrd   $0x34,%r15,%r11
	shr    $0x34,%r15
	mov    $0x30,%r13d
	bzhi   %r13,%r10,%rbx
	mov    %rdx,%r10
	mov    0x18(%rsi),%rdx
	mulx   %rdx,%r8,%rax
	mov    %r10,%rdx
	mulx   0x10(%rsi),%r10,%rbp
	movabs $0xfffffffffffff0,%r13
	and    %r13,%r12
	adox   %r10,%r8
	adox   %rax,%rbp
	adcx   %r8,%r11
	adcx   %r15,%rbp
	mov    %r11,%r15
	shrd   $0x34,%rbp,%r15
	shr    $0x34,%rbp
	mulx   0x18(%rsi),%rax,%r10
	mov    $0x34,%edx
	bzhi   %rdx,%r11,%r8
	adox   %r15,%rax
	adox   %r10,%rbp
	mov    $0x40,%r11d
	bzhi   %r11,%rax,%r15
	shr    $0x30,%rdi
	mov    $0x4,%r10d
	bzhi   %r10,%rdi,%rax
	mov    (%rsi),%rdx
	mulx   %rdx,%rdi,%r10
	or     %rax,%r12
	movabs $0x1000003d1,%rdx
	mulx   %r12,%rax,%r11
	adox   %rax,%rdi
	adox   %r10,%r11
	mov    %rdi,%r10
	shrd   $0x34,%r11,%r10
	shr    $0x34,%r11
	mov    0x8(%rsi),%rdx
	mulx   %rdx,%r12,%rax
	add    -0x40(%rsp),%r12
	adcx   -0x48(%rsp),%rax
	movabs $0x1000003d10,%rdx
	mulx   %r8,%r13,%r9
	add    %r13,%rcx
	adcx   -0x38(%rsp),%r9
	add    %rcx,%r10
	adcx   %r11,%r9
	mov    %r10,%r8
	shrd   $0x34,%r9,%r8
	shr    $0x34,%r9
	mulx   %r15,%r11,%r13
	movabs $0x1000003d10000,%r15
	mov    %rbp,%rdx
	mulx   %r15,%rbp,%rcx
	mov    $0x34,%edx
	bzhi   %rdx,%r10,%r15
	adox   %r12,%r11
	adox   %r13,%rax
	add    %r11,%r8
	adcx   %r9,%rax
	mov    %r8,%r12
	shrd   $0x34,%rax,%r12
	shr    $0x34,%rax
	xor    %r9,%r9
	adox   %rbp,%r14
	adox   %r9,%rcx
	adcx   %r14,%r12
	adcx   %rax,%rcx
	mov    %r12,%r10
	bzhi   %rdx,%rdi,%r13
	bzhi   %rdx,%r10,%rdi
	shrd   $0x34,%rcx,%r12
	shr    $0x34,%rcx
	bzhi   %rdx,%r8,%rbp
	adox   %r12,%rbx
	adox   %r9,%rcx
	mov    -0x50(%rsp),%r11
	mov    %rbx,0x20(%r11)
	mov    %rdi,0x18(%r11)
	mov    %r15,0x8(%r11)
	mov    %r13,(%r11)
	mov    %rbp,0x10(%r11)
	mov    -0x80(%rsp),%rbx
	mov    -0x78(%rsp),%rbp
	mov    -0x70(%rsp),%r12
	mov    -0x68(%rsp),%r13
	mov    -0x60(%rsp),%r14
	mov    -0x58(%rsp),%r15
	ret    
