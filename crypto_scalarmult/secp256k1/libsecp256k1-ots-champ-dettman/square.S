.text
.global CRYPTO_NAMESPACE(fiat_secp256k1_dettman_square)
CRYPTO_NAMESPACE(fiat_secp256k1_dettman_square):
	mov    (%rsi),%rax
	mov    %rax,%r10
	shl    %r10
	mov    0x20(%rsi),%rdx
	mulx   %rdx,%rax,%r11
	mov    0x8(%rsi),%rdx
	lea    (%rdx,%rdx,1),%rcx
	mov    0x10(%rsi),%rdx
	mulx   %rdx,%r8,%r9
	mov    %rcx,%rdx
	mov    %rbx,-0x80(%rsp)
	mulx   0x18(%rsi),%rcx,%rbx
	add    %rcx,%r8
	adcx   %r9,%rbx
	mulx   0x10(%rsi),%r9,%rcx
	mov    %rbp,-0x78(%rsp)
	mov    %rdx,%rbp
	mov    0x20(%rsi),%rdx
	mov    %r12,-0x70(%rsp)
	mov    %r13,-0x68(%rsp)
	mulx   %r10,%r12,%r13
	xor    %rdx,%rdx
	adox   %r12,%r8
	adox   %rbx,%r13
	movabs $0xfffffffffffff,%rbx
	mov    %rax,%r12
	and    %rbx,%r12
	mov    0x18(%rsi),%rdx
	mov    %r14,-0x60(%rsp)
	mov    %r15,-0x58(%rsp)
	mulx   %r10,%r14,%r15
	adox   %r14,%r9
	adox   %rcx,%r15
	movabs $0x1000003d10,%rdx
	mulx   %r12,%rcx,%r14
	adcx   %r9,%rcx
	adcx   %r14,%r15
	mov    %rcx,%r12
	shrd   $0x34,%r15,%r12
	and    %rbx,%rcx
	shrd   $0x34,%r11,%rax
	xor    %r11,%r11
	adox   %r8,%r12
	adox   %r11,%r13
	mulx   %rax,%r8,%r9
	adcx   %r12,%r8
	adcx   %r9,%r13
	mov    %r8,%r14
	shrd   $0x34,%r13,%r14
	and    %rbx,%r8
	mov    0x10(%rsi),%r15
	lea    (%r15,%r15,1),%rax
	mov    %rbp,%rdx
	mulx   0x20(%rsi),%rbp,%r15
	mov    %rax,%rdx
	mulx   0x18(%rsi),%rax,%r12
	mov    %r8,%r9
	shr    $0x30,%r9
	add    %rbp,%rax
	adcx   %r12,%r15
	xor    %r13,%r13
	adox   %rax,%r14
	adox   %r13,%r15
	mov    %r14,%r11
	shrd   $0x34,%r15,%r11
	mov    0x18(%rsi),%rbp
	lea    0x0(%rbp,%rbp,1),%r12
	mulx   0x20(%rsi),%rbp,%rax
	mov    0x18(%rsi),%rdx
	mulx   %rdx,%r15,%r13
	xor    %rdx,%rdx
	adox   %rbp,%r15
	adox   %r13,%rax
	adcx   %r15,%r11
	adc    $0x0,%rax
	mov    %r11,%rbp
	and    %rbx,%rbp
	movabs $0x1000003d10,%r13
	mov    %rbp,%rdx
	mulx   %r13,%rbp,%r15
	mov    %r12,%rdx
	mulx   0x20(%rsi),%r12,%r13
	shrd   $0x34,%rax,%r11
	xor    %rdx,%rdx
	adox   %r12,%r11
	adox   %rdx,%r13
	mov    %r11,%rax
	shrd   $0x34,%r13,%rax
	and    %rbx,%r11
	and    %rbx,%r14
	shl    $0x4,%r14
	lea    (%r14,%r9,1),%r14
	movabs $0x1000003d1,%r9
	mov    %r9,%rdx
	mulx   %r14,%r9,%r12
	mov    (%rsi),%rdx
	mulx   %rdx,%r13,%r14
	xor    %rdx,%rdx
	adox   %r13,%r9
	adox   %r12,%r14
	mov    %r9,%r12
	and    %rbx,%r12
	mov    %r10,%rdx
	mulx   0x8(%rsi),%r10,%r13
	shrd   $0x34,%r14,%r9
	mov    %r12,(%rdi)
	xor    %r14,%r14
	adox   %r10,%r9
	adox   %r14,%r13
	adcx   %r9,%rbp
	adcx   %r15,%r13
	mulx   0x10(%rsi),%r15,%r12
	mov    %rbp,%rdx
	and    %rbx,%rdx
	mov    %rdx,0x8(%rdi)
	mov    0x8(%rsi),%rdx
	mulx   %rdx,%r10,%r9
	adox   %r15,%r10
	adox   %r9,%r12
	movabs $0x1000003d10,%rdx
	mulx   %r11,%r15,%r9
	shrd   $0x34,%r13,%rbp
	xor    %r11,%r11
	adox   %r10,%rbp
	adox   %r11,%r12
	adcx   %rbp,%r15
	adcx   %r9,%r12
	mov    %r15,%r14
	shrd   $0x34,%r12,%r14
	and    %rbx,%r15
	mulx   %rax,%r13,%r10
	movabs $0xffffffffffff,%rax
	and    %rax,%r8
	lea    (%rcx,%r14,1),%rcx
	adox   %rcx,%r13
	adox   %r11,%r10
	mov    %r13,%r9
	shrd   $0x34,%r10,%r9
	lea    (%r8,%r9,1),%r8
	and    %rbx,%r13
	mov    %r8,0x20(%rdi)
	mov    %r13,0x18(%rdi)
	mov    %r15,0x10(%rdi)
	mov    -0x80(%rsp),%rbx
	mov    -0x78(%rsp),%rbp
	mov    -0x70(%rsp),%r12
	mov    -0x68(%rsp),%r13
	mov    -0x60(%rsp),%r14
	mov    -0x58(%rsp),%r15
	ret
